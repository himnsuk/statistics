WEBVTT

00:01.210 --> 00:06.640
The central limit theorem is one of the most important concepts in statistics.

00:06.640 --> 00:12.640
If you had to choose one thing to remember from this course which I hope you don't we'll see in this

00:12.640 --> 00:15.190
lesson is what you want to remember.

00:15.190 --> 00:21.280
The reason for this is the unmatched practical application of the theorem OK.

00:21.450 --> 00:25.940
Let's get started then imagine that you are given a data set.

00:26.070 --> 00:28.180
Its distribution does not matter.

00:28.200 --> 00:33.030
It could be normal uniform binomial or completely random.

00:33.060 --> 00:37.090
The first thing you want to do is start taking out subsets from the data sets.

00:37.230 --> 00:41.070
Or as statisticians call it you start sampling it.

00:41.070 --> 00:45.290
This would allow you to get a better idea of how the entire data is made.

00:45.330 --> 00:46.030
Right.

00:46.400 --> 00:47.160
OK.

00:47.310 --> 00:52.590
Once you have taken a sufficient number of samples and then calculated the mean of each sample will

00:52.590 --> 00:55.300
be able to apply the Central Limit Theorem.

00:55.710 --> 01:01.410
No matter the distribution of the entire data sets binomial uniform or another one.

01:01.410 --> 01:06.940
The means of the samples you took from the entire dataset will approximate a normal distribution.

01:07.860 --> 01:13.350
The more samples you extract and the bigger they are the closer to a normal distribution the sample

01:13.350 --> 01:14.610
means will be.

01:14.640 --> 01:20.640
Moreover their distribution will have the same mean as the original data set and an end times smaller

01:20.640 --> 01:25.050
variance where n is the size of your samples you took from the data sets.

01:25.940 --> 01:28.480
Let's confirm the theorem with an example.

01:28.580 --> 01:33.230
We have prepared 960 random numbers from 1 to 1000.

01:33.230 --> 01:35.180
This is their frequency distribution.

01:35.180 --> 01:42.560
So you are sure that they are randomly picked the mean of this dataset is 489 and its variance is eighty

01:42.560 --> 01:45.370
two thousand eight hundred five.

01:45.390 --> 01:51.480
Let's extract 30 random samples out of the dataset each consisting of 25 numbers.

01:51.840 --> 01:55.540
Remember when we said that the sample should be sufficiently large.

01:55.710 --> 02:01.080
A common rule of thumb is that the sample should be bigger than 25 observations.

02:01.080 --> 02:04.440
The bigger the sample size the better the results you'll get.

02:05.570 --> 02:07.790
So we have our samples.

02:07.790 --> 02:11.810
Now we are going to calculate their means and plot them once again.

02:12.290 --> 02:13.020
OK.

02:13.130 --> 02:14.330
Excellent.

02:14.330 --> 02:18.080
It looks approximately normally distributed doesn't it.

02:18.080 --> 02:21.000
Let's check if the other part of the theorem was right.

02:21.050 --> 02:24.640
The mean of our newly acquired dataset is 492.

02:24.740 --> 02:28.660
While its variants three thousand one hundred seventy one.

02:28.940 --> 02:31.040
Did we expect these numbers.

02:31.040 --> 02:36.680
We anticipated a mean of four hundred eighty nine and a variance of eighty two thousand eight hundred

02:36.680 --> 02:39.080
five divided by 25.

02:39.080 --> 02:46.210
So around three thousand three hundred twelve well when dealing with such big numbers we almost get

02:46.210 --> 02:51.940
the mean right and the variance was not that far off either in the next few lectures you will learn

02:51.940 --> 02:57.190
how to statistically confirm whether such small differences are close enough to the actual result we

02:57.190 --> 03:00.660
expect to obtain spoiler alert.

03:00.850 --> 03:01.530
They are.

03:01.630 --> 03:03.870
And we'll show you why.

03:03.900 --> 03:08.550
So we have learned the main idea behind the Central Limit Theorem.

03:08.600 --> 03:15.230
The key takeaway from this lesson is that the number of samples taken tends towards infinity the distribution

03:15.230 --> 03:18.950
of the mean start approximating a normal distribution.

03:18.950 --> 03:24.950
Imagine their power if your dataset was made up of millions of values and you could afford to sample

03:24.950 --> 03:27.250
just a tiny bit of them.

03:27.320 --> 03:33.850
We can be assuming normally distributed data almost all the time and that's extremely helpful as you

03:33.850 --> 03:38.020
will see later on OK this will do for now.

03:38.040 --> 03:38.880
Thanks for watching.
