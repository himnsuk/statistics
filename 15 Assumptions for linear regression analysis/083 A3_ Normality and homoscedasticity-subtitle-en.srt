1
00:00:00,700 --> 00:00:02,300
Okay great.

2
00:00:02,480 --> 00:00:05,370
So far we've seen assumptions 1 and 2.

3
00:00:05,570 --> 00:00:13,820
Here's the third one it comprises of three parts normality zero mean and homo Adeste history of the

4
00:00:13,820 --> 00:00:15,240
era term.

5
00:00:15,260 --> 00:00:16,860
The first one is easy.

6
00:00:16,880 --> 00:00:20,430
We assumed the error term is normally distributed.

7
00:00:20,450 --> 00:00:26,870
Normal Distribution is not required for creating the regression but for making inferences remember all

8
00:00:26,870 --> 00:00:30,610
regression tables were full of T statistics and statistics.

9
00:00:30,890 --> 00:00:35,780
Well these things work because we assume normality of the error return.

10
00:00:35,840 --> 00:00:40,070
What should we do if the error term is not normally distributed.

11
00:00:40,070 --> 00:00:44,500
You probably remember the theorem we studied earlier in the course right.

12
00:00:44,510 --> 00:00:46,200
Yes that's right.

13
00:00:46,250 --> 00:00:49,520
The central limit theorem for large samples.

14
00:00:49,550 --> 00:00:52,910
The central limit theorem applies for the error terms too.

15
00:00:52,910 --> 00:00:57,320
Therefore we can consider normality as a given for us.

16
00:00:57,340 --> 00:01:00,190
What about a zero mean of error terms.

17
00:01:00,190 --> 00:01:05,620
Well if the mean is not expected to be 0 then the line is not the best fitting one.

18
00:01:05,620 --> 00:01:08,500
However having an intercept solves that problem.

19
00:01:08,500 --> 00:01:15,370
So in real life it is unusual to violate this part of the Assumption and hope most cadet's Tisci.

20
00:01:15,470 --> 00:01:16,720
What's that about.

21
00:01:17,350 --> 00:01:19,510
It means to have equal variance.

22
00:01:19,660 --> 00:01:24,200
So the error terms should have equal variance one with the other.

23
00:01:24,250 --> 00:01:26,810
What if there was a pattern in the variance.

24
00:01:27,250 --> 00:01:31,480
Well an example of a dataset where errors have a different variance.

25
00:01:31,480 --> 00:01:36,510
Looks like this starting close to the regression line and going further away.

26
00:01:36,820 --> 00:01:42,340
This would imply that for smaller values of the independence and dependent variables we would have a

27
00:01:42,340 --> 00:01:44,800
better prediction than for the bigger values.

28
00:01:44,800 --> 00:01:48,850
And I assure you we really don't like this uncertainty.

29
00:01:48,860 --> 00:01:57,280
Let's see a real life example most examples related to income are heteros Godet stick with varying variants.

30
00:01:57,290 --> 00:02:04,310
If a person is poor he or she spends a constant amount of money on food entertainment clothes etc..

31
00:02:04,490 --> 00:02:09,610
The wealthier an individual is the higher the variability of his expenditure.

32
00:02:09,620 --> 00:02:14,890
For example a poor person may be forced to eat eggs or potatoes everyday.

33
00:02:15,050 --> 00:02:17,910
Both meals cost a similar amount of money.

34
00:02:18,260 --> 00:02:24,080
A wealthy person however may go to a fancy gourmet restaurant where truffles are served with expensive

35
00:02:24,080 --> 00:02:28,130
champagne one day and stay home and boil eggs the next day.

36
00:02:28,250 --> 00:02:31,760
The variability of his spending habits is tremendous.

37
00:02:31,760 --> 00:02:36,920
Therefore we expect heteros could TCD well then.

38
00:02:37,110 --> 00:02:44,220
Is there a way to circumvent heteros get past TCD first check for omitted variable bias.

39
00:02:44,220 --> 00:02:45,920
That's always an idea.

40
00:02:46,200 --> 00:02:50,120
After that you can look for outliers and try to remove them.

41
00:02:50,130 --> 00:02:54,180
Finally we shouldn't forget about a statistician's best friend.

42
00:02:54,180 --> 00:02:59,850
The log transformation naturally log stands for a logarithm.

43
00:02:59,850 --> 00:03:05,710
You can change the scale of the graph to a log scale for each observation in the dependent variable

44
00:03:05,970 --> 00:03:12,010
calculate its natural log and then create a regression between the log of Y and the independent X's.

45
00:03:12,240 --> 00:03:19,310
Conversely you can take the independent X that is causing you trouble and do the same let's see an example

46
00:03:20,030 --> 00:03:25,790
this is a scatterplot that represents a high level of heteros get past history on the left hand side

47
00:03:25,790 --> 00:03:26,580
of the chart.

48
00:03:26,660 --> 00:03:30,940
The variance of the error is small while on the right it is high.

49
00:03:30,950 --> 00:03:37,040
Here's the model as x increases by 1 unit y grows by B1 units.

50
00:03:37,880 --> 00:03:43,660
Let's transform the x variable to a new variable called log of X and plot the data.

51
00:03:43,670 --> 00:03:45,650
This is the new result.

52
00:03:45,650 --> 00:03:49,090
Changing the scale of x would reduce the width of the graph.

53
00:03:49,190 --> 00:03:53,210
You can see how the points came closer to each other from left to right.

54
00:03:53,210 --> 00:03:55,830
The new model is called a semi log model.

55
00:03:56,690 --> 00:04:02,060
What if we transform the Y scale instead in a logically to what happened previously.

56
00:04:02,090 --> 00:04:05,400
We would expect the height of the graph to be reduced.

57
00:04:05,420 --> 00:04:07,430
That's the result.

58
00:04:07,470 --> 00:04:10,660
This looks like good linear regression material doesn't it.

59
00:04:10,680 --> 00:04:14,720
The heteros Adeste history we observed earlier is almost gone.

60
00:04:14,730 --> 00:04:18,360
This new model is also called a semi log model.

61
00:04:18,450 --> 00:04:25,130
Its meaning is as x increases by 1 unit Y changes by B 1 percent.

62
00:04:25,140 --> 00:04:28,480
This is a very common transformation.

63
00:04:28,510 --> 00:04:32,890
Sometimes we want or need to change both scales to log.

64
00:04:33,160 --> 00:04:35,860
The result is a log to log model.

65
00:04:36,070 --> 00:04:39,510
We shrink the graph in height and end with.

66
00:04:39,570 --> 00:04:45,160
This is the result the improvement is noticeable but not game changing.

67
00:04:45,180 --> 00:04:49,160
However we may be sure the assumption is not violated.

68
00:04:49,210 --> 00:04:56,830
The interpretation is for each percentage point change in x y changes by B1 percentage points.

69
00:04:56,860 --> 00:05:02,820
If you've done economics you would recognize that such a relationship is known as plasticity.

70
00:05:02,890 --> 00:05:04,780
All right we are done here.

71
00:05:04,870 --> 00:05:07,850
Three assumptions down two to go.

72
00:05:07,870 --> 00:05:08,610
Great work.

