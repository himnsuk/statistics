1
00:00:00,780 --> 00:00:07,260
We already saw the regression equation and an example of a regression model in this lesson we will explore

2
00:00:07,260 --> 00:00:09,840
the determinants of a good regression.

3
00:00:09,840 --> 00:00:12,390
This video is based on the Andover framework.

4
00:00:12,390 --> 00:00:19,830
You may have heard before there are three terms we must define the sum of square totals the sum of squares

5
00:00:19,830 --> 00:00:22,280
regression and the sum of squares error.

6
00:00:23,010 --> 00:00:28,830
The sum of squares total denoted as s t is the square differences between the observed dependent variable

7
00:00:28,920 --> 00:00:30,110
and its mean.

8
00:00:30,120 --> 00:00:34,120
You can think of this as the dispersion of the observed variables around the mean.

9
00:00:34,170 --> 00:00:37,820
Much like the variance we saw in descriptive statistics.

10
00:00:37,960 --> 00:00:42,220
It is a measure of the total variability of the dataset.

11
00:00:42,240 --> 00:00:46,490
The second term is the sum of squares regression or SSR.

12
00:00:46,530 --> 00:00:52,500
It is the sum of differences between the predicted value and the mean of the dependent variable.

13
00:00:52,500 --> 00:00:56,700
Think of it as a measure that describes how well your line fits the data.

14
00:00:56,700 --> 00:01:02,670
If this value of SSR is equal to the sum of squares total It means your regression model captures all

15
00:01:02,670 --> 00:01:06,060
observed variability and is perfect.

16
00:01:06,170 --> 00:01:10,050
The last term is the sum of squares error or SS each.

17
00:01:10,400 --> 00:01:15,500
As we said in one of the previous videos the error is the difference between the observed value and

18
00:01:15,500 --> 00:01:17,030
the predicted value.

19
00:01:17,030 --> 00:01:19,620
We usually want to minimize the error.

20
00:01:19,820 --> 00:01:24,730
The smaller the error the better the estimation power of the regression.

21
00:01:24,750 --> 00:01:28,700
So what is the connection among these three mathematically.

22
00:01:28,770 --> 00:01:32,650
S s t is equal to ss r plus ss e.

23
00:01:32,730 --> 00:01:34,810
The rationale is the following.

24
00:01:34,860 --> 00:01:41,010
The total variability of the data set is equal to the variability explained by the regression line plus

25
00:01:41,010 --> 00:01:44,170
the unexplained variability known as error.

26
00:01:44,580 --> 00:01:46,700
Given a constant total variability.

27
00:01:46,800 --> 00:01:49,880
A lower error will cause a better regression.

28
00:01:49,890 --> 00:01:53,590
Conversely a higher error will cause a less powerful regression.

29
00:01:53,820 --> 00:01:54,890
Makes sense right.

30
00:01:55,790 --> 00:01:56,680
All right.

31
00:01:56,930 --> 00:02:02,700
Based on this knowledge in our next lesson we will learn how to compare different regression models.

32
00:02:02,720 --> 00:02:03,560
Thanks for watching.

